{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import numpy.linalg as linalg\n",
    "import tensorflow as tf\n",
    "slim = tf.contrib.slim\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.io as io\n",
    "\n",
    "import cv2\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./info.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>TimeStamp</th>\n",
       "      <th>POS_X</th>\n",
       "      <th>POS_Y</th>\n",
       "      <th>POS_Z</th>\n",
       "      <th>Q_W</th>\n",
       "      <th>Q_X</th>\n",
       "      <th>Q_Y</th>\n",
       "      <th>Q_Z</th>\n",
       "      <th>IMU_LAX</th>\n",
       "      <th>IMU_LAY</th>\n",
       "      <th>IMU_LAZ</th>\n",
       "      <th>IMU_AVX</th>\n",
       "      <th>IMU_AVY</th>\n",
       "      <th>IMU_AVZ</th>\n",
       "      <th>ImageFile</th>\n",
       "      <th>DepthFile</th>\n",
       "      <th>SegFile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1542098918672</td>\n",
       "      <td>1.628652</td>\n",
       "      <td>-1.342870</td>\n",
       "      <td>-0.038781</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.012323</td>\n",
       "      <td>0.012355</td>\n",
       "      <td>-9.793530</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000238</td>\n",
       "      <td>0.000235</td>\n",
       "      <td>img_0_0_1542098919031247900.png</td>\n",
       "      <td>img_0_3_1542098919034924900.png</td>\n",
       "      <td>img_0_5_1542098919037481300.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1542098927672</td>\n",
       "      <td>0.539220</td>\n",
       "      <td>-0.753961</td>\n",
       "      <td>-0.038781</td>\n",
       "      <td>0.219876</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.975528</td>\n",
       "      <td>-0.004269</td>\n",
       "      <td>-0.007061</td>\n",
       "      <td>-9.796641</td>\n",
       "      <td>-0.000113</td>\n",
       "      <td>0.000299</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>img_0_0_1542098928056216200.png</td>\n",
       "      <td>img_0_3_1542098928058906700.png</td>\n",
       "      <td>img_0_5_1542098928061151600.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1542099006672</td>\n",
       "      <td>1.811826</td>\n",
       "      <td>-1.783541</td>\n",
       "      <td>-0.038781</td>\n",
       "      <td>0.845706</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.533649</td>\n",
       "      <td>0.007127</td>\n",
       "      <td>-0.006138</td>\n",
       "      <td>-9.802512</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000242</td>\n",
       "      <td>-2.073797</td>\n",
       "      <td>img_0_0_1542099007064132600.png</td>\n",
       "      <td>img_0_3_1542099007066469000.png</td>\n",
       "      <td>img_0_5_1542099007068223000.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1542099035673</td>\n",
       "      <td>1.735275</td>\n",
       "      <td>0.055900</td>\n",
       "      <td>-0.038781</td>\n",
       "      <td>0.988930</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.148384</td>\n",
       "      <td>4.352539</td>\n",
       "      <td>3.855151</td>\n",
       "      <td>-9.808618</td>\n",
       "      <td>-0.000499</td>\n",
       "      <td>-0.000436</td>\n",
       "      <td>-1.609914</td>\n",
       "      <td>img_0_0_1542099036029939100.png</td>\n",
       "      <td>img_0_3_1542099036032202400.png</td>\n",
       "      <td>img_0_5_1542099036034012000.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1542099047673</td>\n",
       "      <td>-1.467342</td>\n",
       "      <td>-0.783857</td>\n",
       "      <td>-0.038781</td>\n",
       "      <td>0.127870</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.991791</td>\n",
       "      <td>0.001481</td>\n",
       "      <td>-0.007924</td>\n",
       "      <td>-9.816813</td>\n",
       "      <td>0.000579</td>\n",
       "      <td>0.000273</td>\n",
       "      <td>-0.000102</td>\n",
       "      <td>img_0_0_1542099048061266300.png</td>\n",
       "      <td>img_0_3_1542099048063828800.png</td>\n",
       "      <td>img_0_5_1542099048066488000.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1      TimeStamp     POS_X     POS_Y     POS_Z  \\\n",
       "0           0             0  1542098918672  1.628652 -1.342870 -0.038781   \n",
       "1           1             1  1542098927672  0.539220 -0.753961 -0.038781   \n",
       "2           2             2  1542099006672  1.811826 -1.783541 -0.038781   \n",
       "3           3             3  1542099035673  1.735275  0.055900 -0.038781   \n",
       "4           4             4  1542099047673 -1.467342 -0.783857 -0.038781   \n",
       "\n",
       "        Q_W  Q_X  Q_Y       Q_Z   IMU_LAX   IMU_LAY   IMU_LAZ   IMU_AVX  \\\n",
       "0  1.000000 -0.0  0.0  0.000000 -0.012323  0.012355 -9.793530  0.000031   \n",
       "1  0.219876 -0.0  0.0  0.975528 -0.004269 -0.007061 -9.796641 -0.000113   \n",
       "2  0.845706 -0.0  0.0  0.533649  0.007127 -0.006138 -9.802512  0.000018   \n",
       "3  0.988930 -0.0  0.0  0.148384  4.352539  3.855151 -9.808618 -0.000499   \n",
       "4  0.127870  0.0 -0.0 -0.991791  0.001481 -0.007924 -9.816813  0.000579   \n",
       "\n",
       "    IMU_AVY   IMU_AVZ                        ImageFile  \\\n",
       "0  0.000238  0.000235  img_0_0_1542098919031247900.png   \n",
       "1  0.000299  0.000157  img_0_0_1542098928056216200.png   \n",
       "2  0.000242 -2.073797  img_0_0_1542099007064132600.png   \n",
       "3 -0.000436 -1.609914  img_0_0_1542099036029939100.png   \n",
       "4  0.000273 -0.000102  img_0_0_1542099048061266300.png   \n",
       "\n",
       "                         DepthFile                          SegFile  \n",
       "0  img_0_3_1542098919034924900.png  img_0_5_1542098919037481300.png  \n",
       "1  img_0_3_1542098928058906700.png  img_0_5_1542098928061151600.png  \n",
       "2  img_0_3_1542099007066469000.png  img_0_5_1542099007068223000.png  \n",
       "3  img_0_3_1542099036032202400.png  img_0_5_1542099036034012000.png  \n",
       "4  img_0_3_1542099048063828800.png  img_0_5_1542099048066488000.png  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>TimeStamp</th>\n",
       "      <th>POS_X</th>\n",
       "      <th>POS_Y</th>\n",
       "      <th>POS_Z</th>\n",
       "      <th>Q_W</th>\n",
       "      <th>Q_X</th>\n",
       "      <th>Q_Y</th>\n",
       "      <th>Q_Z</th>\n",
       "      <th>IMU_LAX</th>\n",
       "      <th>IMU_LAY</th>\n",
       "      <th>IMU_LAZ</th>\n",
       "      <th>IMU_AVX</th>\n",
       "      <th>IMU_AVY</th>\n",
       "      <th>IMU_AVZ</th>\n",
       "      <th>ImageFile</th>\n",
       "      <th>DepthFile</th>\n",
       "      <th>SegFile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>995</td>\n",
       "      <td>995</td>\n",
       "      <td>1542108986681</td>\n",
       "      <td>0.065275</td>\n",
       "      <td>-0.236998</td>\n",
       "      <td>-0.038781</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.001377</td>\n",
       "      <td>-0.003358</td>\n",
       "      <td>0.003968</td>\n",
       "      <td>-9.811404</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>-0.051184</td>\n",
       "      <td>img_0_0_1542108986991733400.png</td>\n",
       "      <td>img_0_3_1542108986994579600.png</td>\n",
       "      <td>img_0_5_1542108986996558300.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>996</td>\n",
       "      <td>996</td>\n",
       "      <td>1542109003681</td>\n",
       "      <td>0.485824</td>\n",
       "      <td>-3.605045</td>\n",
       "      <td>-0.038781</td>\n",
       "      <td>0.084121</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.996456</td>\n",
       "      <td>0.465694</td>\n",
       "      <td>-0.761017</td>\n",
       "      <td>-9.808764</td>\n",
       "      <td>0.000285</td>\n",
       "      <td>-0.000134</td>\n",
       "      <td>6.151759</td>\n",
       "      <td>img_0_0_1542109003967920200.png</td>\n",
       "      <td>img_0_3_1542109003971347900.png</td>\n",
       "      <td>img_0_5_1542109003975118000.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>997</td>\n",
       "      <td>997</td>\n",
       "      <td>1542109070681</td>\n",
       "      <td>1.789860</td>\n",
       "      <td>0.275049</td>\n",
       "      <td>-0.038781</td>\n",
       "      <td>0.993484</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.113972</td>\n",
       "      <td>-0.016094</td>\n",
       "      <td>-0.007112</td>\n",
       "      <td>-9.796602</td>\n",
       "      <td>0.000768</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>0.568956</td>\n",
       "      <td>img_0_0_1542109071038894000.png</td>\n",
       "      <td>img_0_3_1542109071041372700.png</td>\n",
       "      <td>img_0_5_1542109071043359600.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>998</td>\n",
       "      <td>998</td>\n",
       "      <td>1542109071681</td>\n",
       "      <td>1.519957</td>\n",
       "      <td>0.138992</td>\n",
       "      <td>-0.038781</td>\n",
       "      <td>0.379602</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.925150</td>\n",
       "      <td>-0.000578</td>\n",
       "      <td>0.004710</td>\n",
       "      <td>-9.812404</td>\n",
       "      <td>-0.000120</td>\n",
       "      <td>0.001153</td>\n",
       "      <td>0.767862</td>\n",
       "      <td>img_0_0_1542109072070706400.png</td>\n",
       "      <td>img_0_3_1542109072073519800.png</td>\n",
       "      <td>img_0_5_1542109072075656700.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>999</td>\n",
       "      <td>999</td>\n",
       "      <td>1542109089681</td>\n",
       "      <td>-2.389804</td>\n",
       "      <td>-3.168592</td>\n",
       "      <td>-0.038781</td>\n",
       "      <td>0.497029</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.867734</td>\n",
       "      <td>0.003071</td>\n",
       "      <td>-0.003072</td>\n",
       "      <td>-9.830379</td>\n",
       "      <td>-0.000036</td>\n",
       "      <td>0.000491</td>\n",
       "      <td>-0.000022</td>\n",
       "      <td>img_0_0_1542109090056128700.png</td>\n",
       "      <td>img_0_3_1542109090058643500.png</td>\n",
       "      <td>img_0_5_1542109090060630900.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0  Unnamed: 0.1      TimeStamp     POS_X     POS_Y     POS_Z  \\\n",
       "995         995           995  1542108986681  0.065275 -0.236998 -0.038781   \n",
       "996         996           996  1542109003681  0.485824 -3.605045 -0.038781   \n",
       "997         997           997  1542109070681  1.789860  0.275049 -0.038781   \n",
       "998         998           998  1542109071681  1.519957  0.138992 -0.038781   \n",
       "999         999           999  1542109089681 -2.389804 -3.168592 -0.038781   \n",
       "\n",
       "          Q_W  Q_X  Q_Y       Q_Z   IMU_LAX   IMU_LAY   IMU_LAZ   IMU_AVX  \\\n",
       "995  0.999999  0.0 -0.0 -0.001377 -0.003358  0.003968 -9.811404  0.000105   \n",
       "996  0.084121  0.0 -0.0 -0.996456  0.465694 -0.761017 -9.808764  0.000285   \n",
       "997  0.993484 -0.0  0.0  0.113972 -0.016094 -0.007112 -9.796602  0.000768   \n",
       "998  0.379602  0.0 -0.0 -0.925150 -0.000578  0.004710 -9.812404 -0.000120   \n",
       "999  0.497029  0.0 -0.0 -0.867734  0.003071 -0.003072 -9.830379 -0.000036   \n",
       "\n",
       "      IMU_AVY   IMU_AVZ                        ImageFile  \\\n",
       "995  0.000134 -0.051184  img_0_0_1542108986991733400.png   \n",
       "996 -0.000134  6.151759  img_0_0_1542109003967920200.png   \n",
       "997  0.000075  0.568956  img_0_0_1542109071038894000.png   \n",
       "998  0.001153  0.767862  img_0_0_1542109072070706400.png   \n",
       "999  0.000491 -0.000022  img_0_0_1542109090056128700.png   \n",
       "\n",
       "                           DepthFile                          SegFile  \n",
       "995  img_0_3_1542108986994579600.png  img_0_5_1542108986996558300.png  \n",
       "996  img_0_3_1542109003971347900.png  img_0_5_1542109003975118000.png  \n",
       "997  img_0_3_1542109071041372700.png  img_0_5_1542109071043359600.png  \n",
       "998  img_0_3_1542109072073519800.png  img_0_5_1542109072075656700.png  \n",
       "999  img_0_3_1542109090058643500.png  img_0_5_1542109090060630900.png  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUTS = ['POS_X','POS_Y','POS_Z', 'Q_W','Q_X','Q_Y','Q_Z']\n",
    "OUTPUTS = ['POS_X','POS_Y', 'Q_W','Q_X','Q_Y','Q_Z']\n",
    "PIVOT = 2 # devide pos and rotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames = data['ImageFile']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = np.asarray(data[OUTPUTS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.628652, -1.34287 ,  1.      , -0.      ,  0.      ,  0.      ])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames = ['./images/' + fname for fname in fnames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = io.imread(fnames[123])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(480, 640, 4)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(im[...,-1], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = np.zeros((len(fnames), im.shape[0], im.shape[1], 3))\n",
    "for idx, f in enumerate(fnames):\n",
    "    im = io.imread(f)\n",
    "    imgs[idx] = im[...,:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_idxs, t_idxs = train_test_split([x for x in range(len(fnames))], test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = imgs[x_idxs]\n",
    "Y_train = targets[x_idxs]\n",
    "X_valid = imgs[t_idxs]\n",
    "Y_valid = targets[t_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "MEAN = [np.mean(Y_train[...,x]) for x in range(len(OUTPUTS))]\n",
    "STD = [np.std(Y_train[...,x])+1e-5 for x in range(len(OUTPUTS))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_normalized = (Y_train - np.array(MEAN)) / np.array(STD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_normalized = -1.0 + 2.0 * X_train / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_norm = lambda x: tf.contrib.layers.layer_norm(inputs=x, center=True, scale=True, activation_fn=None, trainable=True)\n",
    "xavier = tf.contrib.layers.xavier_initializer()\n",
    "\n",
    "\"\"\" 224x224x3\n",
    "(?, 109, 109, 64)\n",
    "(?, 53, 53, 64)\n",
    "(?, 25, 25, 64)\n",
    "(?, 23, 23, 64)\n",
    "\"\"\"\n",
    "\n",
    "\"\"\" 640x480x3\n",
    "(16, 118, 158, 64)\n",
    "(16, 57, 77, 64)\n",
    "(16, 27, 37, 64)\n",
    "(16, 25, 35, 64)\n",
    "\"\"\"\n",
    "\n",
    "# main model\n",
    "# convolution stuff with residual layers (reshape conv to fully connected, connect with others in the end)\n",
    "# several max pools for dim reduction\n",
    "# final layer normalization for smooth surface\n",
    "# didn't use batch norm because batch size to small, will cause reg drawback\n",
    "def model(x, keep_prob, scope=None, reuse=None):\n",
    "    with tf.variable_scope(scope, 'frame', [x], reuse=reuse):\n",
    "        net = slim.conv2d(x, num_outputs=64, kernel_size=5, stride=2, activation_fn=tf.nn.relu, padding='VALID')\n",
    "        net = tf.nn.dropout(net, keep_prob=keep_prob)\n",
    "        net = slim.max_pool2d(net, 3)\n",
    "        # print(net.shape)\n",
    "        aux1 = slim.fully_connected(tf.reshape(net, [-1, 118*158*64]), 128, activation_fn=tf.nn.relu)\n",
    "        \n",
    "        net = slim.conv2d(net, num_outputs=64, kernel_size=3, stride=1, activation_fn=tf.nn.relu, padding='VALID')\n",
    "        net = tf.nn.dropout(net, keep_prob=keep_prob)\n",
    "        net = slim.max_pool2d(net, 3)\n",
    "        # print(net.shape)\n",
    "        aux2 = slim.fully_connected(tf.reshape(net, [-1, 57*77*64]), 128, activation_fn=tf.nn.relu)\n",
    "        \n",
    "        net = slim.conv2d(net, num_outputs=64, kernel_size=3, stride=1, activation_fn=tf.nn.relu, padding='VALID')\n",
    "        net = tf.nn.dropout(net, keep_prob=keep_prob)\n",
    "        net = slim.max_pool2d(net, 3)\n",
    "        # print(net.shape)\n",
    "        aux3 = slim.fully_connected(tf.reshape(net, [-1,27*37*64]), 128, activation_fn=tf.nn.relu)\n",
    "        \n",
    "        net = slim.conv2d(net, num_outputs=64, kernel_size=3, stride=1, activation_fn=tf.nn.relu, padding='VALID')\n",
    "        net = tf.nn.dropout(net, keep_prob=keep_prob)\n",
    "        # net = slim.max_pool2d(net, 3)\n",
    "        # print(net.shape)\n",
    "        aux4 = slim.fully_connected(tf.reshape(net, [-1,25*35*64]), 128, activation_fn=tf.nn.relu)\n",
    "        \n",
    "        net = slim.fully_connected(tf.reshape(net, [-1, 25*35*64]), 256, activation_fn=tf.nn.relu)\n",
    "        net = tf.nn.dropout(x=net, keep_prob=keep_prob)\n",
    "        net = slim.fully_connected(net, 128, activation_fn=tf.nn.relu)\n",
    "        return layer_norm(tf.nn.elu(net + aux1 + aux2 + aux3 + aux4))\n",
    "        # return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ret = model(X_normalized[:16],.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ret = model(x[:16], .25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embed_xyz = tf.get_variable(\"ret1\",[128, 3], dtype=tf.float32,initializer=xavier)\n",
    "# embed_quat = tf.get_variable(\"ret2\",[128, 4],dtype=tf.float32,initializer=xavier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xyz_preds = tf.matmul(tf.cast(ret, tf.float32), embed_xyz)\n",
    "# quat_preds = tf.matmul(tf.cast(ret, tf.float32), embed_quat)\n",
    "# res = tf.concat([xyz, quat], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.random.randn(3,4).dot(np.random.randn(4,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.reduce_mean(tf.squared_difference(targets[:16], res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize valid data using mean from train dataset; it's important, yes\n",
    "Y_valid_normalized = (Y_valid - np.array(MEAN)) / np.array(STD)\n",
    "X_valid_normalized = -1.0 + 2.0 * X_valid / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0219 23:06:08.153893 140693558556416 deprecation.py:506] From <ipython-input-21-4f25066e5e4e>:26: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0219 23:06:09.032235 140693558556416 deprecation.py:506] From /home/antares/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/slot_creator.py:187: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      " Step: 49 | 50 Train loss : 7.71560  \n",
      " Valid loss: 3.53837 Mean norm: 2.0307 Mean quat diff: 35.9146 \n",
      "Epoch: 1\n",
      " Step: 49 | 50 Train loss : 2.43183 \n",
      " Valid loss: 3.48262 Mean norm: 1.7358 Mean quat diff: 33.0860 \n",
      "Epoch: 2\n",
      " Step: 49 | 50 Train loss : 1.90341 \n",
      " Valid loss: 3.35797 Mean norm: 1.6413 Mean quat diff: 30.9623 \n",
      "Epoch: 3\n",
      " Step: 49 | 50 Train loss : 1.44827 \n",
      " Valid loss: 3.11608 Mean norm: 1.6222 Mean quat diff: nan 591 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/antares/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: RuntimeWarning: invalid value encountered in arccos\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Valid loss: 3.24684 Mean norm: 1.6619 Mean quat diff: nan \n",
      "Epoch: 4\n",
      " Step: 49 | 50 Train loss : 1.14997 \n",
      " Valid loss: 3.20420 Mean norm: 1.6438 Mean quat diff: 28.8759 \n",
      "Epoch: 5\n",
      " Step: 49 | 50 Train loss : 0.94196 \n",
      " Valid loss: 3.16702 Mean norm: 1.6337 Mean quat diff: 27.7530 \n",
      "Epoch: 6\n",
      " Step: 49 | 50 Train loss : 0.78927 \n",
      " Valid loss: 3.14614 Mean norm: 1.4950 Mean quat diff: 25.4432 \n",
      "Epoch: 7\n",
      " Step: 49 | 50 Train loss : 0.68649 \n",
      " Valid loss: 2.98753 Mean norm: 1.4567 Mean quat diff: 23.6318 \n",
      "Epoch: 8\n",
      " Step: 49 | 50 Train loss : 0.65640 \n",
      " Valid loss: 3.10415 Mean norm: 1.4094 Mean quat diff: 23.4501 \n",
      "Epoch: 9\n",
      " Step: 49 | 50 Train loss : 0.60592 \n",
      " Valid loss: 3.25719 Mean norm: 1.3660 Mean quat diff: 23.7924 \n",
      "Epoch: 10\n",
      " Step: 49 | 50 Train loss : 0.62338 \n",
      " Valid loss: 3.14790 Mean norm: 1.2891 Mean quat diff: 23.6196 \n",
      "Epoch: 11\n",
      " Step: 49 | 50 Train loss : 0.61680 \n",
      " Valid loss: 3.37376 Mean norm: 1.1965 Mean quat diff: 20.3136 \n",
      "Epoch: 12\n",
      " Step: 49 | 50 Train loss : 0.71737 \n",
      " Valid loss: 3.39611 Mean norm: 1.2859 Mean quat diff: 20.7063 \n",
      "Epoch: 13\n",
      " Step: 49 | 50 Train loss : 0.61289 \n",
      " Valid loss: 3.04195 Mean norm: 1.2498 Mean quat diff: 21.4074 \n",
      "Epoch: 14\n",
      " Step: 49 | 50 Train loss : 0.55232 \n",
      " Valid loss: 3.11766 Mean norm: 1.1579 Mean quat diff: 20.2135 \n",
      "Epoch: 15\n",
      " Step: 49 | 50 Train loss : 0.36393 \n",
      " Valid loss: 3.12797 Mean norm: 1.1055 Mean quat diff: 19.8710 \n",
      "Epoch: 16\n",
      " Step: 49 | 50 Train loss : 0.33664 \n",
      " Valid loss: 2.96521 Mean norm: 1.0876 Mean quat diff: 20.4741 \n",
      "Epoch: 17\n",
      " Step: 49 | 50 Train loss : 0.40382 \n",
      " Valid loss: 2.63670 Mean norm: 0.9914 Mean quat diff: 19.2417 \n",
      "Epoch: 18\n",
      " Step: 49 | 50 Train loss : 0.59650 \n",
      " Valid loss: 2.44101 Mean norm: 0.9142 Mean quat diff: 19.9249 \n",
      "Epoch: 19\n",
      " Step: 49 | 50 Train loss : 0.58208 \n",
      " Valid loss: 2.69756 Mean norm: 0.9062 Mean quat diff: 18.9845 \n",
      "Epoch: 20\n",
      " Step: 49 | 50 Train loss : 0.38534 \n",
      " Valid loss: 2.76252 Mean norm: 0.9469 Mean quat diff: 19.7092 \n",
      "Epoch: 21\n",
      " Step: 49 | 50 Train loss : 0.34030 \n",
      " Valid loss: 2.98933 Mean norm: 0.9150 Mean quat diff: 18.5185 \n",
      "Epoch: 22\n",
      " Step: 49 | 50 Train loss : 0.39528 \n",
      " Valid loss: 2.91932 Mean norm: 0.9366 Mean quat diff: 19.3747 \n",
      "Epoch: 23\n",
      " Step: 49 | 50 Train loss : 0.44969 \n",
      " Valid loss: 2.89106 Mean norm: 0.9181 Mean quat diff: 17.5508 \n",
      "Epoch: 24\n",
      " Step: 49 | 50 Train loss : 0.28525 \n",
      " Valid loss: 2.79320 Mean norm: 0.8902 Mean quat diff: 19.4342 \n",
      "Epoch: 25\n",
      " Step: 49 | 50 Train loss : 0.18266 \n",
      " Valid loss: 2.78948 Mean norm: 0.8913 Mean quat diff: 19.5464 \n",
      "Epoch: 26\n",
      " Step: 49 | 50 Train loss : 0.16152 \n",
      " Valid loss: 2.82397 Mean norm: 0.8762 Mean quat diff: 19.9243 \n",
      "Epoch: 27\n",
      " Step: 49 | 50 Train loss : 0.14390 \n",
      " Valid loss: 2.79670 Mean norm: 0.8787 Mean quat diff: 19.2713 \n",
      "Epoch: 28\n",
      " Step: 49 | 50 Train loss : 0.14369 \n",
      " Valid loss: 2.73675 Mean norm: 0.8848 Mean quat diff: 18.9339 \n",
      "Epoch: 29\n",
      " Step: 49 | 50 Train loss : 0.13809 \n",
      " Valid loss: 2.69558 Mean norm: 0.8717 Mean quat diff: 19.5977 \n",
      "Epoch: 30\n",
      " Step: 49 | 50 Train loss : 0.17190 \n",
      " Valid loss: 2.60166 Mean norm: 0.8931 Mean quat diff: 21.2422 \n",
      "Epoch: 31\n",
      " Step: 49 | 50 Train loss : 0.33134 \n",
      " Valid loss: 2.73983 Mean norm: 0.9348 Mean quat diff: 22.2374 \n",
      "Epoch: 32\n",
      " Step: 49 | 50 Train loss : 0.39227 \n",
      " Valid loss: 2.80892 Mean norm: 0.9071 Mean quat diff: 20.2315 \n",
      "Epoch: 33\n",
      " Step: 49 | 50 Train loss : 0.23117 \n",
      " Valid loss: 2.63867 Mean norm: 0.8631 Mean quat diff: 19.6801 \n",
      "Epoch: 34\n",
      " Step: 49 | 50 Train loss : 0.16021 \n",
      " Valid loss: 2.78970 Mean norm: 0.8376 Mean quat diff: 18.0022 \n",
      "Epoch: 35\n",
      " Step: 49 | 50 Train loss : 0.14622 \n",
      " Valid loss: 2.76221 Mean norm: 0.8441 Mean quat diff: 18.2360 \n",
      "Epoch: 36\n",
      " Step: 49 | 50 Train loss : 0.10418 \n",
      " Valid loss: 2.82131 Mean norm: 0.8235 Mean quat diff: nan 680 \n",
      "Epoch: 37\n",
      " Step: 49 | 50 Train loss : 0.07680 \n",
      " Valid loss: 2.86937 Mean norm: 0.8248 Mean quat diff: 17.8208 \n",
      "Epoch: 38\n",
      " Step: 49 | 50 Train loss : 0.08411 \n",
      " Valid loss: 2.94113 Mean norm: 0.8322 Mean quat diff: 17.6513 \n",
      "Epoch: 39\n",
      " Step: 49 | 50 Train loss : 0.11195 \n",
      " Valid loss: 3.08858 Mean norm: 0.8416 Mean quat diff: 17.4787 \n",
      "Epoch: 40\n",
      " Step: 49 | 50 Train loss : 0.13962 \n",
      " Valid loss: 3.26594 Mean norm: 0.8450 Mean quat diff: 17.4258 \n",
      "Epoch: 41\n",
      " Step: 49 | 50 Train loss : 0.10895 \n",
      " Valid loss: 3.08689 Mean norm: 0.8282 Mean quat diff: 17.7949 \n"
     ]
    }
   ],
   "source": [
    "BS = 16 # batch_size\n",
    "\n",
    "def _quaternion_diff(q1, q2):\n",
    "    acos = np.arccos(np.inner(q1, q2)/(linalg.norm(q1)*linalg.norm(q2)))\n",
    "    return np.rad2deg(acos)\n",
    "\n",
    "def _diff(u, v):\n",
    "    return np.linalg.norm(u-v)\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    # basic VARs for inputs/labels/dropout and learning rate\n",
    "    learning_rate = tf.placeholder_with_default(input=5e-4, shape=())\n",
    "    keep_prob = tf.placeholder_with_default(input=.25, shape=())\n",
    "    aux_cost = tf.placeholder_with_default(input=5.0, shape=())\n",
    "    inputs = tf.placeholder(shape=(None, \n",
    "                                   X_normalized.shape[1], \n",
    "                                   X_normalized.shape[2], \n",
    "                                   X_normalized.shape[3]), \n",
    "                            dtype=tf.float32)\n",
    "    xyz_labels = tf.placeholder(shape=(None, PIVOT), dtype=tf.float32)\n",
    "    quat_labels = tf.placeholder(shape=(None, len(OUTPUTS)-PIVOT), dtype=tf.float32)\n",
    "    embeddings = model(inputs, keep_prob)\n",
    "\n",
    "    with tf.variable_scope(\"xyz\"):\n",
    "        embed_xyz = tf.get_variable(\"ret1\",\n",
    "                                   [128, PIVOT],\n",
    "                                   dtype=tf.float32,\n",
    "                                   initializer=xavier,\n",
    "                                   )\n",
    "    with tf.variable_scope(\"quat\"):\n",
    "        embed_quat = tf.get_variable(\"ret2\",\n",
    "                           [128, len(OUTPUTS)-PIVOT],\n",
    "                           dtype=tf.float32,\n",
    "                           initializer=xavier,\n",
    "                           )\n",
    "        \n",
    "    # embedings to predictions -> two heads\n",
    "    xyz_preds = tf.matmul(embeddings, embed_xyz)\n",
    "    quat_preds = tf.matmul(embeddings, embed_quat)\n",
    "    # res = tf.concat([xyz, quat], axis=1)\n",
    "    # loss_xyz = tf.losses.absolute_difference(xyz_labels, xyz_preds)\n",
    "    # loss_qut = tf.losses.absolute_difference(quat_preds - tf.div(quat_labels, tf.norm(quat_labels)))\n",
    "    \n",
    "    # Define loss as in paper(mb, i'm not sure..) + l2 weight regularization\n",
    "    loss = tf.reduce_mean(tf.squared_difference(xyz_labels, xyz_preds)) + 5.0 * tf.reduce_mean(tf.squared_difference(quat_labels, quat_preds))#(\n",
    "    #    aux_cost * tf.reduce_mean(tf.norm(quat_preds - tf.math.divide(quat_labels, tf.norm(quat_labels))))\n",
    "    #)\n",
    "    w_reg = tf.add_n([tf.nn.l2_loss(v) for v in tf.trainable_variables()]) * 1e-7\n",
    "    loss += w_reg\n",
    "    \n",
    "    # concat final predictions\n",
    "    #tf.cast(quat_preds, tf.float64)\n",
    "    res = tf.concat([xyz_preds, quat_preds], axis=1)\n",
    "\n",
    "    # optimization stuff\n",
    "    opt = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)\n",
    "    preds = (res * STD) + MEAN\n",
    "    \n",
    "    # do epoch function for main train procedure\n",
    "    # or for valid/test predictions\n",
    "    def do_epoch(sess, mode='train'):\n",
    "        l_mean = []\n",
    "        if mode == 'train':\n",
    "            for i in range(X_normalized.shape[0]//BS):\n",
    "                xs = X_normalized[i*BS:i*BS+BS]\n",
    "                ys = Y_normalized[i*BS:i*BS+BS]\n",
    "                feed_dict={inputs : xs, xyz_labels : ys[:,:PIVOT], quat_labels : ys[:,PIVOT:]}\n",
    "                if i > 30:\n",
    "                    feed_dict.update({learning_rate : 1e-5})\n",
    "                out, l, _ = sess.run([preds, loss, opt], feed_dict=feed_dict)\n",
    "                l_mean.append(l)\n",
    "                print('\\r', 'Step: %d' % i, '|', (800//BS), 'Train loss : %.5f' % np.mean(l_mean), end=' ')\n",
    "            print()\n",
    "        elif mode == 'valid':\n",
    "            d_mean = []\n",
    "            q_mean = []\n",
    "            for i in range(X_valid_normalized.shape[0]//BS):\n",
    "                xs = X_valid_normalized[i*BS:i*BS+BS]\n",
    "                # no need to in data normalization here\n",
    "                ys = Y_valid[i*BS:i*BS+BS]\n",
    "                feed_dict={inputs : xs, keep_prob : 1.0, xyz_labels : ys[:,:PIVOT], quat_labels: ys[:,PIVOT:]}\n",
    "                out, l = sess.run([preds, loss], feed_dict=feed_dict)\n",
    "                for i in range(BS):\n",
    "                    d_mean.append(_diff(ys[i,:PIVOT], out[i,:PIVOT]))\n",
    "                    q_mean.append(_quaternion_diff(ys[i,PIVOT:], out[i,PIVOT:]))\n",
    "                l_mean.append(l)\n",
    "                print('\\r', 'Valid loss: %.5f' % np.mean(l_mean), \n",
    "                      'Mean norm: %.4f' % np.mean(d_mean), \n",
    "                      'Mean quat diff: %.4f' % np.mean(q_mean), end=' ')\n",
    "            print()\n",
    "        return np.mean(l_mean) if mode == 'train' else (np.mean(l_mean), out)\n",
    "\n",
    "    valid_score = None\n",
    "    with tf.Session(config=config) as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        for epoch in range(42):\n",
    "            l_mean = []\n",
    "            print('Epoch: %d' % epoch)\n",
    "            score = do_epoch(sess)\n",
    "            if valid_score == None or score < valid_score:\n",
    "                valid_score, out = do_epoch(sess, 'valid')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
